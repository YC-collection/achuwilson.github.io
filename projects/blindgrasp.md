---
title: "BlindGrasp -  Robot grasping using only tactile senses in visually inaccessible environments"
author: achu
layout: post
permalink: /projects/blindgrasp
categories:
  - Research
  - Manipulation
  - Grasping
  
 
     
excerpt: "BlindGrasp -   Robot grasping using only tactile senses in visually inaccessible environments"
---


The sense of touch is one of the most powerful and amazing senses that humans have. It provides rich information about the environment that we make contact with.  It is so powerfull that the visually impaired people mainly explores the world using the sense of touch. Even for the normal people, the sense of touch is deeply intewined with our brain that we often use it unconsiously. For example, we would not look into our pocket before grabbing a coin or key from it. Still, everytime, we can succesfully do it. We can succesfull grasp items from visually inaccessible areas using the sense of touch only


**Project BlindGrasp aims to explore the usage of tactile sensing for grasping in unstructured and visually inaccessible environments**. 

Tactile sensing in robots are not widely used unlike the vision systems. Probably too much dependance on the vision systems may have made us ignore the rich information provided by the tactile sensing.The unavailability of high resoultion tactile sensors may also have been a reason for this. Most of the approaches on using tactile sensing are just confined to the detection of slip or quality of grasp, estimating mechanical properties like hardness of objects etc. 


I came to know about Gelsight at ICRA 2017 from a couple of MIT PhD students( Wenzhen Yuan, Greg Izzat & Geronimo Mirano) working on it. They were at ICRA to present their research on using Gelsight to augment the 3D pointcloud generated by the vision systems.


{% include image.html url="https://farm5.staticflickr.com/4482/37886429841_a45491c7a8_k.jpg" caption="My fingerprint on the Gelsight Gripper " href="https://farm5.staticflickr.com/4482/37886429841_a45491c7a8_k.jpg" width=600 align="center" %}

## **Project Goals:**

Blindgrasp needs both research into mechanical structure of the Gelsight gripper and the software algorithms to make sense of the data. They are as follows.

<br>
**1. GelSight Finger**

  The original GelSight gripper consists of a planar sensing area of size 24x18mm. It works well for tasks like estimating hardness of objects, generating pointclouds for object recognition etc. But it will be inefficient for exploring tasks in clutter, since it can only see forces coming from a single direction. The traditional two finger gripper is good for grasping tasks, but would perform poor in exploring through the clutter because of its non-streamline shape. In case of human fingerrs, they are  elliptical cylinder in shape with the most sensitive area as the inner flattened surface. So, one of the hardware enhancements would be to model and design a curved Gelsight sensor and gripper. It is best illustrated in the figure below
  
 <br>
{% include image.html url="/images/gelsight_curved.png" href="../projects/blindgrasp" caption="Tactile exploration in clutter would require a curved GelSight Gripper" width=600  align="center" %}

<br>
  

  In addition to the mechanical design,this would also include non linear remapping of the touch information on the curved surface onto the planar camera sensor 
  <br>
  

  
  
**2. Tactile exploration using Deep Reinforcement Learning**

   This involves developing a tactile exploration policy for the control of a manipulator. The exploration policy would generate control commands (joint torques) for the manipulator based on tactile feedback such that it can search through a cluttered environment and pick up the desired object.The goal is to  picking up a coin from a tray filled with small spherical marbles. This would be a good scenario to justify the usage of tactile exploration, as it would be impossible to detect the coin with vision when it is buried under the marbles. 

<br>
The initial approach would be to use a deep reinforcement learning based agent to pick up the coin. The agent will have to explore by moving the robot's end effector and digging through the marbles. It will be given positive rewards when it comes in contact with the coin and a final grand reward when it picks up the coin. This would also involve developing of new reinforcement agents which will work well with sparse rewards since the exploration phase would be often having zero rewards. 

<br>
{% include image.html url="/images/kuka_env_marbles.png" caption="Yes, there is a hidden gold coin under the marbles,  the robot has to dig through it, find the coin and pick it up." width=600  align="center" %}



<br>

## Update-1 : Nov-22-2017: Simulation of the original Planar Gelsight Sensor

I tried to simulate Gelsight when I was right back from the conference. The initial approach was to simulate it in Drake as directed by Greg, but installing Drake and getting it working was a real mess. So, I began trying in Gazebo. But that also did not turn out well since I could not get the contact sensing to work reliably. Then I tried the physics simulator Bullet. It had softbody simulation, which I thought would be useful for simulating the elastomer of GelSight. But it turned out that the softbody simulation was a basic and needed much more development. So, I indirectly modelled Gelsight using the raytest functionality in bullet. It returns the depth at which a ray makes contact with a solid body.

 
 Following is the  video of the simulated gelsight gripper. The Kuka iiwa has a WSG 50 gripper fitted with a gelsight sensor. The sensor has a sensing area of 24x24mm and has a resolution of 256x256 pixels in the planar sensing area. It outputs standard ROS 3D pointcloud data, which is displayed in RViz.The simulation was run in my laptop and the pointcloud could be generated at 5Hz

 <div align="center">
<iframe width="640" height="480" src="https://www.youtube.com/embed/IO02smLcDQE" frameborder="0" allowfullscreen></iframe>
</div>

The next steps would be to model, simulate and prototype the curved Gelsight gripper. At the same time, I have to strengthen my reinforcement learning skills. Follow me on twitter for updates.












<br>
